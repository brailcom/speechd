<preface>

  <title>Preface</title>

  <para>
    Speech Daemon project comes to provide a device independent layer for
    speech synthesis. It should provide a simple interface for client
    applications (applications, that want to speak) as well as for device
    driver modules (for particular speech synthesis).
  </para>

  <para>
    High quality speech synthesis has been available for a long time and now
    it's usable even by ordinary users on their home PC's. It comes sometimes
    as a necesity, sometimes as a good feature for programs to provide speech
    output.  There is a wide field of possible uses from educational software,
    through specialized systems (hospitals, laboratories) and friendlier user
    interfaces to software for our visually impaired fellows. This is exactly
    where Speech Daemon came from.
  </para>
  <para>
    Ordinary users don't meet speech synthesis too often and I would say that
    it's power is often underpreciated.  But for blind people it's one of the
    few ways how to communicate with computer. They are living with speech
    synthesis each day so it should be no surprise that it were they who
    realised for the first time that the current situation with speech
    synthesis on the GNU/Linux system is a great chaos.
  </para>
  <para>
    There are different speech synthetisers with different capabilities.  Some
    of them are hardware, some of them are software. Some of them are Free
    Software and are available on the internet. However, none of them is
    preinstalled in one of the widely used GNU/Linux distributions. Programmers
    have really hard times when they want to make their program speak because
    they need to find some suitable synthetiser (long hours of experiments and
    so on...) and then make it work with their program. They often need to
    write output device drivers for these programs or hardware devices and are
    doing it again and again. You can imagine it all fails when an innocent
    user executes two programs with speech output at once -- if they even start
    both (what I doubt), they will be shouting one over the other. This makes
    it very hard for programmers to insert speech support to their programs
    (for blind users or simple for making better user interface) and it's one
    of the reasons we still don't fully exploit what speech synthesis
    technology offers.
  </para>
  <para>
    In an ideal world, programmers could use similar commands for speech
    synthesis as they do for normal text output (printf, puts, ...). In an
    ideal world, there would be some speech_printf() that would take care of
    saying your message in the right time without interumping others, without
    you beeing obligated to take care of how exactly the communication with
    speech synthetiser is implemented and without you having to worry about
    what synthetiser to use and if it's available. In an ideal world, there
    would be some speech synthetiser in each GNU/Linux distribution and some
    speech dispatcher taking care of all applications that want to speak,
    allowing user to configure speech parameters and providing simple interface
    (as speech_printf()) through some shared library for programmers. It will
    be a long way until we get archieve this state of things, but with Speech
    Daemon, we are taking the first steps...
  </para>
  
</preface>
